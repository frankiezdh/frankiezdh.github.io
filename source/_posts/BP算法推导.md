---
title: BP算法推导
date: 2018-03-20 16:26:24
tags: [人工神经网络, 算法]
---

人工智能/深度学习这两年是热门的点。其中的人工神经网络是基础，而反向传播算法是人工神经网络的基础。[维基百科](https://zh.wikipedia.org/wiki/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95) 上是这么介绍反向传播算法的。

```quota
反向传播（英语：Back Propagation，缩写为BP）是“误差反向传播”的简称，是一种与最优化方法（如梯度下降法）结合使用的，用来训练人工神经网络的常见方法。该方法计算对网络中所有权重计算损失函数的梯度。这个梯度会反馈给最优化方法，用来更新权值以最小化损失函数。
```
<!--more-->

下面尝试对一个全连接的人工神经网络BP算法的推导。


人工神经网络一般如下

![network.jpg](https://i.loli.net/2018/03/20/5ab0d0a9cb48b.jpg)


对一个单独的神经元特写：

![神经元.png](https://i.loli.net/2018/03/20/5ab0d57763f2a.png)


BP算法的目的就是通过输出和预设值的方差，对Wijk进行调整，并不断迭代，直到方差最小——是不是很眼熟，没错，和这篇文章[golang实现梯度下降算法](https://frankiezdh.github.io/2018/03/19/golang%E5%AE%9E%E7%8E%B0%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95/) 是一样的思想。

顺着这个思路，其实整个BP算法的核心就是求解误差对Wijk的偏导。下图演示了偏导的计算过程。
![bp算法.png](https://i.loli.net/2018/03/20/5ab0d2d03c325.png)